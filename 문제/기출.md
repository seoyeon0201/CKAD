## Q1. 시크릿을 생성하고 `시크릿의 값을 pod의 환경변수로 가져오기`

## A1

1. Secret 생성
- `dotfile-secret`이라는 이름의 secret 생성

`kubectl create secret generic dotfile-secret [--type=string] [--from-file=[key=]source] [--from-literal=key1=value1] [--dry-run=server|client|none] [options]`

2. Pod의 환경변수로 가져오기

- (1) spec.volumes에서 secret을 volume으로 정의 후 (2) volumeMounts

`pod.yaml`
```
apiVersion: v1
kind: Pod
metadata:
  name: secret-dotfiles-pod
spec:
  volumes:
    - name: secret-volume
      secret:
        secretName: dotfile-secret  #secret 사용
  containers:
    - name: dotfile-test-container
      image: registry.k8s.io/busybox
      command:
        - ls
        - "-l"
        - "/etc/secret-volume"
      volumeMounts:
        - name: secret-volume
          readOnly: true
          mountPath: "/etc/secret-volume"
```

## Q2. resource-request를 이용한 pod 리소스 제한

- spec.containers.resources.requests 또는 spec.containers.resources.limits와 같이 container 내에서 requests와 limits 설정해 리소스 관리

`pod.yaml`
```
apiVersion: v1
kind: Pod
metadata:
  name: frontend
spec:
  containers:
  - name: app
    image: images.my-company.example/app:v4
    resources:  
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
  - name: log-aggregator
    image: images.my-company.example/log-aggregator:v6
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```


## Q3. readiness Probe 추가

- spec.containers.readinessProbe 또는 spec.containers.livenessProbe와 같이 container 내에서 설정

`pod.yaml`
```
apiVersion: v1
kind: Pod
metadata:
  name: goproxy
  labels:
    app: goproxy
spec:
  containers:
  - name: goproxy
    image: registry.k8s.io/goproxy:0.1
    ports:
    - containerPort: 8080
    readinessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 15
      periodSeconds: 10
    livenessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 15
      periodSeconds: 10
```


## Q4. service account 를 pod 에 추가

1. ServiceAccount 생성

- sa1이라는 이름의 serviceaccount 생성

`kubectl create serviceaccount sa1 [--dry-run=server|client|none] [options]`

2. Pod에 적용

`pod.yaml`
```
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: pod2
  name: pod2
spec:
  serviceAccountName: sa1     #serviceaccount 적용
  automountServiceAccountToken: false
  containers:
  - image: nginx
    name: pod2
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
```


## Q5. docker 이미지 빌드하고 tar파일로 save 하는 문제



#### Q1. Docker 이미지 빌드:
#### ⭐️ A1
    - Dockerfile이 `/data/ckad/build/apache-php/Dockerfile`에 위치한다고 가정합니다.
    - 다음 명령어를 사용하여 Docker 이미지를 빌드합니다:
        
        ```bash
        docker build -t apache-php:ckad-v1 /data/ckad/build/apache-php
        ```
        
    - 이 명령어는 `apache-php`라는 이미지 이름과 `ckad-v1`이라는 태그를 가진 이미지를 빌드합니다.

#### Q2. Docker 이미지 저장:

#### ⭐️ A2
    - 다음 명령어를 사용하여 빌드한 Docker 이미지를 tar 파일로 저장합니다:
        
        ```bash
        docker save -o /data/ckad/apache-php-ckad-v1.tar apache-php:ckad-v1
        ```
        
    - 이 명령어는 `apache-php:ckad-v1` 이미지를 `apache-php-ckad-v1.tar`라는 파일로 저장합니다.
    - `o` 옵션은 출력 파일을 지정하는 데 사용되며, 파일 경로는 `/data/ckad/apache-php-ckad-v1.tar`로 설정되어 있습니다.

## Q6. depoly 버전업되어서 yaml 수정하기

⭐️ api랑 selector 등을 수정해야 함

## Q7. deploy yaml 수정하고 롤링업데이트 진행하기

- `--record`를 하지 않는 경우, `k rollout history deployment deploy-rollout` 명령에 대해서 변경사유가 표시되지 않음

```bash
# rolling update
kubectl set image deployment eshop-payment nginx=nginx:1.17 --record  

kubectl rollout history deployment eshop-payment

# rollback
kubectl rollout undo deployment eshop-payment
```

## Q8. 카나리 배포중에 current와 canary가 있는데 canary가 트래픽의 30퍼센트 받도록 service를 수정

#### ⭐️ 강의에 카나리 배포 내용 다시 듣기

- Max파드가 10개고 canary가 30%정도 비율이여야 함
    1. canary 디플로이를 만들고 current와 공유하는 label을 붙인다.
    2. current pod를 7개, canary pod를 3개로 설정한다.
    3. 서비스가 current와 canary가 공유하는 label을 select하도록 설정한다.

## Q9. pod의 security context에서 권한 승격불가능하고, uid 20000으로 사용

`pod.yaml`
```
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 20000
  volumes:
  - name: sec-ctx-vol
    emptyDir: {}
  containers:
  - name: sec-ctx-demo
    image: busybox:1.28
    command: [ "sh", "-c", "sleep 1h" ]
    volumeMounts:
    - name: sec-ctx-vol
      mountPath: /data/demo
    securityContext:
      allowPrivilegeEscalation: false
```

## Q10. networkpolicy newpod가 db, web 하고만 통신가능하도록 수정

⭐️ 강의 다시 듣고 문제도 다시 풀기

⭐️ 네트워크 팔러시 절대 건들지 말고 접근해야하는 파드만 고칠것

>네트워크 정책 4개 있음
>1. all-access → db, web 파드에 붙이기
>2. default deny
>3. web access → new pod 에 붙이기
>4. db access → new pod 에 붙이기

- 아래 ingress에 맞게 pod의 label 수정 !

`networkpolicy.yaml`
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
```

⭐️ db, web 파드는 all-access netpol 붙이고 newpod는 db, web과 통신할 수 있는 netpol과 연결하도록 label 수정한다

## Q11. ingress / service / deploy가 주어졌을 때, deploy 수정하지 않고, service와 ingress만 수정해서 응답값을 받아오는 문제

> - 주어진 url에 맞게 host, path 값을 수정
> - service 이름도 수정
> - 파드의 컨테이너 포트와 서비스의 포트, ingress가 연결되도록 포트 설정 꼼꼼히 할 것
> - curl로 테스트했을때 html 문서가 출력되어야 함

## Q12. limits 문제

문제 : pod가 실행이 안되는데 request 값을 맞춰주고, limits 값는 namespace에서 제한한 값의 절반으로 해야함.

⭐️ **해당 namespace의 limit range를 살펴보고** 그것의 절반값으로 설정해야 함

- `k get limitranges`

> limit range는 namespace 단위로 적용된다. 아래 예시
`limitrange.yaml`
```
apiVersion: v1
kind: LimitRange
metadata:
  name: my-limit-range
spec:
  limits:
  - type: Container
    defaultRequest:
      cpu: 100m
      memory: 256Mi
    defaultLimit:
      cpu: 200m
      memory: 512Mi
    maxLimitRequestRatio:
      cpu: 4
      memory: 2
    min:
      cpu: 50m
      memory: 128Mi
    max:
      cpu: 500m
      memory: 1Gi
```

## Q13. Cronjob 만들기

> - 주어진 pod에 대한 컨테이너 정보
> - 5번의 성공
> - 2번의 실패 허용
> - 10분마다 진행
> - 파드는 8초 뒤에 삭제
> - 크론잡의 템플릿을 복사해 다른 잡을 만들고 실행해야 함

```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: my-cronjob
spec:
  schedule: "*/10 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: my-container
            image: your-image:latest
            command: ["sh", "-c", "your-command"]
          restartPolicy: OnFailure
  backoffLimit: 2   # 최대 리트라이 횟수
  completions: 5     # 성공해야 하는 작업의 수
  activeDeadlineSeconds: 8  # 최대 실행 시간 (초)
```

⭐️ Kubernetes 공식 페이지의 `Cheatsheet` 보기

⭐️ `kubectl config get-contexts`로 현재 context 확인하고 진행하기
- 만약 context가 맞지 않으면 `kubectl config use-context [CONTEXT NAME]`으로 변경
